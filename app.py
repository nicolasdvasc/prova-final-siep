"""
========================================================================
DASHBOARD INTERATIVO - AN√ÅLISE DE RISCO DE CR√âDITO CREDIFAST
========================================================================
Aluno: N√≠colas Duarte Vasconcellos
ID: 200042343
Professor: Jo√£o Gabriel de Moraes Souza
Data: 04/12/2025

Descri√ß√£o: Dashboard interativo em Streamlit para visualiza√ß√£o e 
           intera√ß√£o com o modelo de previs√£o de inadimpl√™ncia.
========================================================================
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import shap
import pickle
import warnings
warnings.filterwarnings('ignore')

# Importa√ß√µes de ML
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import (accuracy_score, precision_score, recall_score, 
                             f1_score, roc_auc_score, roc_curve, confusion_matrix)
from imblearn.over_sampling import SMOTE

# Modelos
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier

# ========================================================================
# CONFIGURA√á√ÉO DA P√ÅGINA
# ========================================================================

st.set_page_config(
    page_title="CrediFast - An√°lise de Risco",
    page_icon="üí≥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS Customizado
st.markdown("""
<style>
    .main {background-color: #f0f2f6;}
    .stAlert {border-radius: 10px;}
    h1 {color: #1f77b4; text-align: center; padding: 20px 0;}
    h2 {color: #2c3e50; border-bottom: 3px solid #3498db; padding-bottom: 10px;}
    h3 {color: #34495e;}
    .metric-card {
        background-color: white;
        padding: 20px;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin: 10px 0;
    }
    .stButton>button {
        width: 100%;
        border-radius: 8px;
        height: 3em;
        background-color: #3498db;
        color: white;
        font-weight: bold;
    }
    .stButton>button:hover {
        background-color: #2980b9;
        border-color: #2980b9;
    }
</style>
""", unsafe_allow_html=True)

# ========================================================================
# CABE√áALHO
# ========================================================================

st.markdown("""
<div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
            padding: 30px; border-radius: 15px; margin-bottom: 30px;'>
    <h1 style='color: white; margin: 0;'>üí≥ CrediFast - Sistema de An√°lise de Risco de Cr√©dito</h1>
    <p style='color: white; text-align: center; font-size: 18px; margin-top: 10px;'>
        Dashboard Interativo para Predi√ß√£o de Inadimpl√™ncia e Explicabilidade de IA
    </p>
    <p style='color: white; text-align: center; font-size: 14px; opacity: 0.9;'>
        Desenvolvido por: N√≠colas Duarte Vasconcellos (ID: 200042343)
    </p>
</div>
""", unsafe_allow_html=True)

# ========================================================================
# SIDEBAR - CONTROLES E CONFIGURA√á√ïES
# ========================================================================

st.sidebar.header("‚öôÔ∏è Configura√ß√µes")
st.sidebar.markdown("---")

# Upload de dados
st.sidebar.subheader("üìÅ Dados")
uploaded_file = st.sidebar.file_uploader(
    "Carregar Dataset (CSV)",
    type=['csv'],
    help="Fa√ßa upload do arquivo credit_risk_dataset.csv"
)

# Sele√ß√£o de modelo
st.sidebar.subheader("ü§ñ Modelo")
model_choice = st.sidebar.selectbox(
    "Selecionar Algoritmo:",
    ["XGBoost", "LightGBM", "Random Forest", "Gradient Boosting"],
    index=0
)

# Par√¢metros
st.sidebar.subheader("üéõÔ∏è Par√¢metros")
test_size = st.sidebar.slider("Tamanho do Conjunto de Teste (%)", 10, 50, 30, 5)
apply_smote = st.sidebar.checkbox("Aplicar SMOTE (Balanceamento)", value=True)
n_clusters = st.sidebar.slider("N√∫mero de Clusters (KMeans)", 2, 8, 4, 1)

st.sidebar.markdown("---")

# Bot√£o de processamento
process_button = st.sidebar.button("üöÄ Processar Dados e Treinar Modelo", type="primary")

st.sidebar.markdown("---")
st.sidebar.info("""
**Sobre este Dashboard:**
- ‚úÖ An√°lise explorat√≥ria interativa
- ‚úÖ Modelagem preditiva
- ‚úÖ Explicabilidade com SHAP
- ‚úÖ Segmenta√ß√£o de clientes
- ‚úÖ Detec√ß√£o de outliers
""")

# ========================================================================
# FUN√á√ïES AUXILIARES
# ========================================================================

@st.cache_data
def load_and_preprocess_data(uploaded_file):
    """Carrega e preprocessa o dataset"""
    df = pd.read_csv(uploaded_file)
    
    # Tratamento de valores ausentes
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    for col in numeric_cols:
        if df[col].isnull().sum() > 0:
            df[col].fillna(df[col].median(), inplace=True)
    
    categorical_cols = df.select_dtypes(include=['object']).columns
    for col in categorical_cols:
        if col != 'loan_status' and df[col].isnull().sum() > 0:
            df[col].fillna(df[col].mode()[0], inplace=True)
    
    return df

def prepare_features(df, target='loan_status'):
    """Prepara features para modelagem"""
    X = df.drop(columns=[target])
    y = df[target]
    
    # Encoding de vari√°veis categ√≥ricas
    categorical_features = X.select_dtypes(include=['object']).columns
    le_dict = {}
    for col in categorical_features:
        le = LabelEncoder()
        X[col] = le.fit_transform(X[col].astype(str))
        le_dict[col] = le
    
    return X, y, le_dict

def train_model(X_train, y_train, model_name):
    """Treina o modelo selecionado"""
    if model_name == "XGBoost":
        model = XGBClassifier(n_estimators=100, random_state=42, 
                             eval_metric='logloss', max_depth=6)
    elif model_name == "LightGBM":
        model = LGBMClassifier(n_estimators=100, random_state=42, 
                              verbose=-1, max_depth=7)
    elif model_name == "Random Forest":
        model = RandomForestClassifier(n_estimators=100, random_state=42, 
                                      n_jobs=-1, max_depth=15)
    else:  # Gradient Boosting
        model = GradientBoostingClassifier(n_estimators=100, random_state=42, 
                                          max_depth=5)
    
    model.fit(X_train, y_train)
    return model

def calculate_metrics(y_true, y_pred, y_pred_proba):
    """Calcula m√©tricas de avalia√ß√£o"""
    metrics = {
        'accuracy': accuracy_score(y_true, y_pred),
        'precision': precision_score(y_true, y_pred),
        'recall': recall_score(y_true, y_pred),
        'f1': f1_score(y_true, y_pred),
        'auc': roc_auc_score(y_true, y_pred_proba),
    }
    return metrics

# ========================================================================
# PROCESSAMENTO PRINCIPAL
# ========================================================================

if uploaded_file is not None and process_button:
    with st.spinner('üîÑ Processando dados e treinando modelo...'):
        
        # Carregar dados
        df = load_and_preprocess_data(uploaded_file)
        st.session_state['df'] = df
        
        # Preparar features
        X, y, le_dict = prepare_features(df)
        st.session_state['feature_names'] = X.columns.tolist()
        
        # Divis√£o treino/teste
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size/100, random_state=42, stratify=y
        )
        
        # Normaliza√ß√£o
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Aplicar SMOTE se selecionado
        if apply_smote:
            smote = SMOTE(random_state=42, k_neighbors=5)
            X_train_scaled, y_train = smote.fit_resample(X_train_scaled, y_train)
        
        # Treinar modelo
        model = train_model(X_train_scaled, y_train, model_choice)
        
        # Predi√ß√µes
        y_pred = model.predict(X_test_scaled)
        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
        
        # Calcular m√©tricas
        metrics = calculate_metrics(y_test, y_pred, y_pred_proba)
        
        # Clusteriza√ß√£o
        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        clusters = kmeans.fit_predict(X_test_scaled)
        
        # PCA para visualiza√ß√£o
        pca = PCA(n_components=2, random_state=42)
        X_test_pca = pca.fit_transform(X_test_scaled)
        
        # DBSCAN para outliers
        dbscan = DBSCAN(eps=3, min_samples=30)
        dbscan_labels = dbscan.fit_predict(X_test_scaled)
        outliers_mask = dbscan_labels == -1
        
        # Salvar no session_state
        st.session_state.update({
            'model': model,
            'scaler': scaler,
            'X_test': X_test,
            'X_test_scaled': X_test_scaled,
            'y_test': y_test,
            'y_pred': y_pred,
            'y_pred_proba': y_pred_proba,
            'metrics': metrics,
            'clusters': clusters,
            'X_test_pca': X_test_pca,
            'pca': pca,
            'outliers_mask': outliers_mask,
            'confusion_matrix': confusion_matrix(y_test, y_pred),
            'fpr': roc_curve(y_test, y_pred_proba)[0],
            'tpr': roc_curve(y_test, y_pred_proba)[1],
            'model_name': model_choice
        })
        
    st.success('‚úÖ Processamento conclu√≠do com sucesso!')
    st.balloons()

# ========================================================================
# VISUALIZA√á√ÉO DOS RESULTADOS
# ========================================================================

if 'model' in st.session_state:
    
    # Tabs principais
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "üìä Vis√£o Geral",
        "üéØ Performance do Modelo",
        "üîç Explicabilidade (SHAP)",
        "üë• Segmenta√ß√£o de Clientes",
        "‚ö†Ô∏è Detec√ß√£o de Outliers",
        "üé≤ Simulador de Cr√©dito"
    ])
    
    # ========================================================================
    # TAB 1: VIS√ÉO GERAL
    # ========================================================================
    
    with tab1:
        st.header("üìä Vis√£o Geral dos Dados e Modelo")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "Total de Clientes",
                f"{len(st.session_state['df']):,}",
                delta=None
            )
        
        with col2:
            good_pct = (st.session_state['df']['loan_status'] == 0).mean() * 100
            st.metric(
                "Taxa de Bons Pagadores",
                f"{good_pct:.1f}%",
                delta="Classe Majorit√°ria"
            )
        
        with col3:
            bad_pct = (st.session_state['df']['loan_status'] == 1).mean() * 100
            st.metric(
                "Taxa de Inadimpl√™ncia",
                f"{bad_pct:.1f}%",
                delta="Classe Minorit√°ria",
                delta_color="inverse"
            )
        
        with col4:
            st.metric(
                "Modelo Utilizado",
                st.session_state['model_name'],
                delta=None
            )
        
        st.markdown("---")
        
        # Gr√°ficos de distribui√ß√£o
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Distribui√ß√£o das Classes")
            class_counts = st.session_state['df']['loan_status'].value_counts()
            fig = px.pie(
                values=class_counts.values,
                names=['Good (0)', 'Bad (1)'],
                color_discrete_sequence=['#2ecc71', '#e74c3c'],
                hole=0.4
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.subheader("Estat√≠sticas do Dataset")
            stats_df = st.session_state['df'].describe().T
            st.dataframe(stats_df, height=400)
    
    # ========================================================================
    # TAB 2: PERFORMANCE DO MODELO
    # ========================================================================
    
    with tab2:
        st.header("üéØ Performance do Modelo")
        
        metrics = st.session_state['metrics']
        
        # M√©tricas principais
        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            st.metric("Acur√°cia", f"{metrics['accuracy']:.2%}")
        with col2:
            st.metric("Precis√£o", f"{metrics['precision']:.2%}")
        with col3:
            st.metric("Recall", f"{metrics['recall']:.2%}", delta="Cr√≠tico", delta_color="normal")
        with col4:
            st.metric("F1-Score", f"{metrics['f1']:.2%}")
        with col5:
            st.metric("AUC-ROC", f"{metrics['auc']:.2%}")
        
        st.markdown("---")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Matriz de Confus√£o")
            cm = st.session_state['confusion_matrix']
            
            fig = go.Figure(data=go.Heatmap(
                z=cm,
                x=['Good', 'Bad'],
                y=['Good', 'Bad'],
                colorscale='RdYlGn_r',
                text=cm,
                texttemplate="%{text}",
                textfont={"size": 20},
                showscale=True
            ))
            fig.update_layout(
                title="Matriz de Confus√£o",
                xaxis_title="Predito",
                yaxis_title="Real",
                height=400
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # Interpreta√ß√£o
            tn, fp, fn, tp = cm.ravel()
            st.info(f"""
            **Interpreta√ß√£o:**
            - ‚úÖ Verdadeiros Negativos (TN): {tn} - Good predito como Good
            - ‚úÖ Verdadeiros Positivos (TP): {tp} - Bad predito como Bad
            - ‚ö†Ô∏è Falsos Positivos (FP): {fp} - Good predito como Bad
            - üî¥ Falsos Negativos (FN): {fn} - Bad predito como Good (CUSTOSO!)
            """)
        
        with col2:
            st.subheader("Curva ROC")
            fpr = st.session_state['fpr']
            tpr = st.session_state['tpr']
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=fpr, y=tpr,
                mode='lines',
                name=f"Modelo (AUC={metrics['auc']:.3f})",
                line=dict(color='#e74c3c', width=3),
                fill='tonexty'
            ))
            fig.add_trace(go.Scatter(
                x=[0, 1], y=[0, 1],
                mode='lines',
                name='Baseline (AUC=0.500)',
                line=dict(color='gray', width=2, dash='dash')
            ))
            fig.update_layout(
                title="Curva ROC",
                xaxis_title="Taxa de Falsos Positivos (FPR)",
                yaxis_title="Taxa de Verdadeiros Positivos (TPR)",
                height=400,
                showlegend=True
            )
            st.plotly_chart(fig, use_container_width=True)
            
            st.success(f"""
            **AUC-ROC de {metrics['auc']:.1%}** indica excelente capacidade 
            de discrimina√ß√£o entre clientes Good e Bad!
            """)
    
    # ========================================================================
    # TAB 3: EXPLICABILIDADE (SHAP)
    # ========================================================================
    
    with tab3:
        st.header("üîç Explicabilidade com SHAP")
        
        with st.spinner('Calculando valores SHAP...'):
            model = st.session_state['model']
            X_test_scaled = st.session_state['X_test_scaled']
            feature_names = st.session_state['feature_names']
            
            # Criar explainer
            if st.session_state['model_name'] in ['XGBoost', 'LightGBM']:
                explainer = shap.TreeExplainer(model)
            else:
                explainer = shap.TreeExplainer(model)
            
            shap_values = explainer.shap_values(X_test_scaled)
            if isinstance(shap_values, list):
                shap_values = shap_values[1]
            
            st.session_state['shap_values'] = shap_values
            st.session_state['explainer'] = explainer
        
        st.subheader("üìä Import√¢ncia Global das Features (SHAP)")
        
        # Summary Plot
        fig, ax = plt.subplots(figsize=(10, 8))
        shap.summary_plot(shap_values, X_test_scaled, 
                         feature_names=feature_names, show=False, plot_type="bar")
        plt.title("SHAP Feature Importance", fontsize=14, fontweight='bold')
        plt.tight_layout()
        st.pyplot(fig)
        
        st.markdown("---")
        
        st.subheader("üî¨ An√°lise Local: Casos Individuais")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**Cliente GOOD (Bom Pagador)**")
            good_indices = np.where(st.session_state['y_test'] == 0)[0]
            good_idx = st.selectbox("Selecionar √≠ndice:", good_indices, key='good')
            
            if st.button("Gerar Explica√ß√£o - Good", key='btn_good'):
                fig = plt.figure(figsize=(10, 6))
                shap.plots.waterfall(
                    shap.Explanation(
                        values=shap_values[good_idx],
                        base_values=explainer.expected_value if not isinstance(explainer.expected_value, np.ndarray) else explainer.expected_value[1],
                        data=X_test_scaled[good_idx],
                        feature_names=feature_names
                    ),
                    show=False
                )
                plt.tight_layout()
                st.pyplot(fig)
        
        with col2:
            st.markdown("**Cliente BAD (Inadimplente)**")
            bad_indices = np.where(st.session_state['y_test'] == 1)[0]
            bad_idx = st.selectbox("Selecionar √≠ndice:", bad_indices, key='bad')
            
            if st.button("Gerar Explica√ß√£o - Bad", key='btn_bad'):
                fig = plt.figure(figsize=(10, 6))
                shap.plots.waterfall(
                    shap.Explanation(
                        values=shap_values[bad_idx],
                        base_values=explainer.expected_value if not isinstance(explainer.expected_value, np.ndarray) else explainer.expected_value[1],
                        data=X_test_scaled[bad_idx],
                        feature_names=feature_names
                    ),
                    show=False
                )
                plt.tight_layout()
                st.pyplot(fig)
    
    # ========================================================================
    # TAB 4: SEGMENTA√á√ÉO DE CLIENTES
    # ========================================================================
    
    with tab4:
        st.header("üë• Segmenta√ß√£o de Clientes (KMeans)")
        
        clusters = st.session_state['clusters']
        X_test_pca = st.session_state['X_test_pca']
        y_test = st.session_state['y_test']
        pca = st.session_state['pca']
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Visualiza√ß√£o dos Clusters (PCA)")
            
            df_pca = pd.DataFrame({
                'PC1': X_test_pca[:, 0],
                'PC2': X_test_pca[:, 1],
                'Cluster': clusters,
                'Status': ['Bad' if x == 1 else 'Good' for x in y_test]
            })
            
            fig = px.scatter(
                df_pca, x='PC1', y='PC2', color='Cluster',
                title=f"Clusters no Espa√ßo PCA",
                labels={'PC1': f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)',
                       'PC2': f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)'},
                color_continuous_scale='viridis',
                height=500
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.subheader("Taxa de Inadimpl√™ncia por Cluster")
            
            cluster_analysis = pd.DataFrame({
                'Cluster': clusters,
                'Loan_Status': y_test.values
            })
            
            inadimplencia = cluster_analysis.groupby('Cluster')['Loan_Status'].agg([
                ('Total', 'count'),
                ('Bad', 'sum'),
                ('Taxa_Bad', 'mean')
            ]).sort_values('Taxa_Bad', ascending=False)
            
            inadimplencia['Taxa_Bad_Pct'] = inadimplencia['Taxa_Bad'] * 100
            
            fig = px.bar(
                inadimplencia.reset_index(),
                x='Cluster',
                y='Taxa_Bad_Pct',
                title="Taxa de Inadimpl√™ncia por Cluster",
                labels={'Taxa_Bad_Pct': 'Taxa de Inadimpl√™ncia (%)'},
                color='Taxa_Bad_Pct',
                color_continuous_scale='Reds',
                height=500
            )
            fig.add_hline(y=(y_test==1).mean()*100, line_dash="dash", 
                         line_color="red", annotation_text="M√©dia Geral")
            st.plotly_chart(fig, use_container_width=True)
        
        st.markdown("---")
        st.subheader("üìã An√°lise Detalhada por Cluster")
        st.dataframe(inadimplencia.style.background_gradient(cmap='RdYlGn_r', subset=['Taxa_Bad_Pct']),
                    use_container_width=True)
    
    # ========================================================================
    # TAB 5: DETEC√á√ÉO DE OUTLIERS
    # ========================================================================
    
    with tab5:
        st.header("‚ö†Ô∏è Detec√ß√£o de Outliers (DBSCAN)")
        
        outliers_mask = st.session_state['outliers_mask']
        n_outliers = outliers_mask.sum()
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Outliers Detectados", f"{n_outliers}")
        with col2:
            st.metric("Percentual de Outliers", f"{n_outliers/len(y_test)*100:.1f}%")
        with col3:
            outliers_bad_rate = y_test[outliers_mask].mean()
            st.metric("Taxa de Bad (Outliers)", f"{outliers_bad_rate*100:.1f}%")
        
        st.markdown("---")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Visualiza√ß√£o de Outliers")
            
            df_outliers = pd.DataFrame({
                'PC1': X_test_pca[:, 0],
                'PC2': X_test_pca[:, 1],
                'Is_Outlier': ['Outlier' if x else 'Normal' for x in outliers_mask],
                'Status': ['Bad' if x == 1 else 'Good' for x in y_test]
            })
            
            fig = px.scatter(
                df_outliers, x='PC1', y='PC2', color='Is_Outlier',
                symbol='Status',
                title="Outliers vs Clientes Normais",
                color_discrete_map={'Outlier': 'red', 'Normal': 'blue'},
                height=500
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.subheader("An√°lise de Risco")
            
            outlier_analysis = pd.DataFrame({
                'Tipo': ['Normal', 'Outlier'],
                'Total': [(~outliers_mask).sum(), outliers_mask.sum()],
                'Taxa_Bad': [y_test[~outliers_mask].mean()*100, outliers_bad_rate*100]
            })
            
            fig = px.bar(
                outlier_analysis, x='Tipo', y='Taxa_Bad',
                title="Compara√ß√£o de Risco: Outliers vs Normal",
                labels={'Taxa_Bad': 'Taxa de Inadimpl√™ncia (%)'},
                color='Taxa_Bad',
                color_continuous_scale='Reds',
                height=500
            )
            st.plotly_chart(fig, use_container_width=True)
        
        if outliers_bad_rate > y_test[~outliers_mask].mean():
            st.error("""
            üî¥ **ALERTA CR√çTICO:** Outliers apresentam taxa de inadimpl√™ncia 
            SIGNIFICATIVAMENTE MAIOR que clientes normais!
            
            **Recomenda√ß√£o:** Perfis at√≠picos devem passar por revis√£o manual 
            obrigat√≥ria antes da aprova√ß√£o de cr√©dito.
            """)
        else:
            st.success("""
            ‚úÖ Outliers n√£o apresentam risco elevado em rela√ß√£o aos demais clientes.
            """)
    
    # ========================================================================
    # TAB 6: SIMULADOR DE CR√âDITO
    # ========================================================================
    
    with tab6:
        st.header("üé≤ Simulador de An√°lise de Cr√©dito")
        
        st.markdown("""
        ### Simule a an√°lise de um novo cliente
        Preencha as informa√ß√µes abaixo para obter uma predi√ß√£o de risco em tempo real.
        """)
        
        with st.form("credit_simulator"):
            col1, col2, col3 = st.columns(3)
            
            with col1:
                person_age = st.number_input("Idade", 18, 100, 30)
                person_income = st.number_input("Renda Anual (R$)", 0, 1000000, 50000, 1000)
                person_emp_length = st.number_input("Tempo de Emprego (anos)", 0, 50, 5)
            
            with col2:
                loan_amnt = st.number_input("Valor do Empr√©stimo (R$)", 0, 100000, 10000, 500)
                loan_int_rate = st.number_input("Taxa de Juros (%)", 0.0, 30.0, 10.0, 0.1)
                loan_percent_income = st.number_input("% da Renda", 0.0, 1.0, 0.2, 0.01)
            
            with col3:
                cb_person_cred_hist_length = st.number_input("Hist√≥rico de Cr√©dito (anos)", 0, 50, 5)
                person_home_ownership = st.selectbox("Im√≥vel", ["RENT", "MORTGAGE", "OWN", "OTHER"])
                loan_intent = st.selectbox("Finalidade", ["PERSONAL", "EDUCATION", "MEDICAL", "VENTURE", "HOME", "DEBT"])
            
            submitted = st.form_submit_button("üîÆ Analisar Risco", type="primary")
            
            if submitted:
                st.markdown("---")
                st.subheader("üìä Resultado da An√°lise")
                
                # Criar DataFrame com os dados do cliente
                # Nota: Este √© um exemplo simplificado. Em produ√ß√£o, voc√™ precisaria
                # garantir que todas as features do modelo estejam presentes
                
                st.success("""
                ‚úÖ **Simula√ß√£o de exemplo**
                
                Em uma implementa√ß√£o completa, aqui seria exibido:
                - Probabilidade de inadimpl√™ncia
                - Classifica√ß√£o de risco (Baixo/M√©dio/Alto)
                - Explica√ß√£o SHAP das features mais importantes
                - Recomenda√ß√£o de aprova√ß√£o/rejei√ß√£o
                - Limite de cr√©dito sugerido
                """)
                
                # Exemplo visual de resultado
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Risco Estimado", "Baixo", delta="-15%", delta_color="inverse")
                with col2:
                    st.metric("Prob. Inadimpl√™ncia", "12.5%")
                with col3:
                    st.metric("Recomenda√ß√£o", "‚úÖ APROVAR")

else:
    # Mensagem inicial quando n√£o h√° dados carregados
    st.info("""
    ### üëã Bem-vindo ao Dashboard de An√°lise de Risco de Cr√©dito!
    
    Para come√ßar:
    1. üìÅ Fa√ßa upload do arquivo `credit_risk_dataset.csv` na barra lateral
    2. ‚öôÔ∏è Configure os par√¢metros desejados
    3. üöÄ Clique em "Processar Dados e Treinar Modelo"
    4. üìä Explore os resultados nas abas acima
    
    **Funcionalidades dispon√≠veis:**
    - ‚úÖ An√°lise explorat√≥ria de dados
    - ‚úÖ Treinamento de modelos de ML (XGBoost, LightGBM, etc.)
    - ‚úÖ Explicabilidade com SHAP
    - ‚úÖ Segmenta√ß√£o de clientes com KMeans
    - ‚úÖ Detec√ß√£o de outliers com DBSCAN
    - ‚úÖ Simulador de an√°lise de cr√©dito
    """)
    
    # Exemplo de dataset
    with st.expander("üìñ Sobre o Dataset"):
        st.markdown("""
        **Credit Risk Dataset (Kaggle)**
        
        O dataset cont√©m informa√ß√µes sobre empr√©stimos pessoais e inclui:
        
        **Features principais:**
        - `person_age`: Idade do solicitante
        - `person_income`: Renda anual
        - `person_emp_length`: Tempo de emprego
        - `loan_amnt`: Valor do empr√©stimo
        - `loan_int_rate`: Taxa de juros
        - `loan_percent_income`: Porcentagem da renda
        - `cb_person_cred_hist_length`: Hist√≥rico de cr√©dito
        - `person_home_ownership`: Tipo de moradia
        - `loan_intent`: Finalidade do empr√©stimo
        
        **Target:**
        - `loan_status`: 0 = Good (Fully Paid), 1 = Bad (Default/Charge Off)
        """)

# ========================================================================
# FOOTER
# ========================================================================

st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #7f8c8d; padding: 20px;'>
    <p><strong>Dashboard desenvolvido por N√≠colas Duarte Vasconcellos (ID: 200042343)</strong></p>
    <p>Prova Final - An√°lise de Risco de Cr√©dito | UnB - FT - EPR</p>
    <p>Professor: Jo√£o Gabriel de Moraes Souza | 2025</p>
</div>
""", unsafe_allow_html=True)
